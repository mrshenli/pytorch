#pragma once

#include <torch/csrc/distributed/spmd/event.h>

#include <vector>

#include <ATen/core/ivalue.h>
#include <c10d/ProcessGroup.hpp>
#include <torch/csrc/autograd/engine.h>
#include <torch/csrc/autograd/functions/accumulate_grad.h>
#include <torch/csrc/autograd/utils/lambda_post_hook.h>
#include <torch/csrc/utils/memory.h>


namespace torch {
namespace distributed {
namespace spmd {

using c10::ivalue::Future;
using c10::IValue;

namespace {

template <class T>
std::vector<std::shared_ptr<Future>> createOneFutureEvent(c10::intrusive_ptr<T> event) {
    auto future = std::make_shared<Future>(at::AnyClassType::get());
    future->markCompleted(IValue(c10::static_intrusive_pointer_cast<Event>(event)));
    std::vector<std::shared_ptr<Future>> futures;
    futures.reserve(1);
    futures.emplace_back(std::move(future));
    return futures;
}

} // namespace

class EventHandler {
 public:
  virtual std::vector<EventSchema> ingressEvents() = 0;
  virtual std::vector<EventSchema> egressEvents() = 0;
  // returned Future contents Event objects generated by this handler.
  virtual std::vector<std::shared_ptr<Future>> handleEvent(
      const c10::intrusive_ptr<Event>&) = 0;
};

class RootHandler : public EventHandler {
 public:
  std::vector<EventSchema> ingressEvents() override {
    return {};
  }

  std::vector<EventSchema> egressEvents() override {
    return {
        EventType::PREPARE_MODULE,
        EventType::PRE_FORWARD,
        EventType::POST_FORWARD};
  }

  std::vector<std::shared_ptr<Future>> handleEvent(
      const c10::intrusive_ptr<Event>& /* unused */) override {
    TORCH_INTERNAL_ASSERT(false);
  }
};


class DefaultTrigger : public EventHandler {
 public:
  std::vector<EventSchema> ingressEvents() override {
    return {EventType::PREPARE_MODULE};
  }

  std::vector<EventSchema> egressEvents() override {
    return {EventType::LOCAL_GRAD_READY};
  }

  std::vector<std::shared_ptr<Future>> handleEvent(
      const c10::intrusive_ptr<Event>& event) override {
    switch (event->schema().type_) {
      case EventType::PREPARE_MODULE: {
        return handlePrepareModule(
            c10::static_intrusive_pointer_cast<PrepareModuleEvent>(event));
      }
      default:
        TORCH_INTERNAL_ASSERT(false, "unexcepted event type");
    }
  }

 private:
  std::vector<std::shared_ptr<Future>> handlePrepareModule(
      c10::intrusive_ptr<PrepareModuleEvent> event) {
    std::cout << "PREPARE_MODULE: " << event->parameters().size()
              << ", inserting hooks!" << std::endl << std::flush;

    params_ = event->parameters();
    std::vector<std::shared_ptr<Future>> futures;
    futures.reserve(params_.size());
    for (size_t index = 0; index < params_.size(); ++index) {
      auto& param = params_[index];
      futures.emplace_back(std::make_shared<Future>(at::AnyClassType::get()));

      auto gradAccumulator =
          torch::autograd::impl::grad_accumulator(param);
      // Hook to execute after the gradient accumulator has executed.
      gradAccumulator->add_post_hook(
          torch::make_unique<torch::autograd::utils::LambdaPostHook>(
              [this, index, localGradReadyFuture=futures.back()](
                  const torch::autograd::variable_list& outputs,
                  const torch::autograd::variable_list& /* unused */) {
                autogradHook(index, localGradReadyFuture);
                return outputs;
              }));
      gradAccumulators_.push_back(std::move(gradAccumulator));
    }
    return futures;
  }

  void autogradHook(
      size_t index,
      const std::shared_ptr<Future>& localGradReadyFuture) {
    auto lgr = c10::make_intrusive<LocalGradReadyEvent>(
        index, params_[index].mutable_grad());

    localGradReadyFuture->markCompleted(
        IValue(c10::static_intrusive_pointer_cast<Event>(lgr)));

    if (index == 0) {

    }
  }

  // keep grad accumulators alive
  std::vector<std::shared_ptr<torch::autograd::Node>> gradAccumulators_;
  std::vector<at::Tensor> params_;
};

class DefaultBucketer : public EventHandler {
 public:
  // FIXME: we might need more advanced ingress/egress event specifications.
  // E.g., LOCAL_GRAD_READY -> BUCKET_READY; COMM_DONE -> GLOBAL_GRAD_READY,
  // otherwise, DefaultBucketer and AllReduceComm can form a cycle.
  std::vector<EventSchema> ingressEvents() override {
    // FIXME: consume PREPARE_MODULE to allocate buckets
    return {
        EventType::PREPARE_MODULE,
        EventType::LOCAL_GRAD_READY,
        EventType::COMM_DONE};
  }

  std::vector<EventSchema> egressEvents() override {
    return {EventType::BUCKET_READY, EventType::GLOBAL_GRAD_READY};
  }

  std::vector<std::shared_ptr<Future>> handleEvent(
      const c10::intrusive_ptr<Event>& event) override {
    switch (event->schema().type_) {
      case EventType::PREPARE_MODULE: {
        return handlePrepareModule(
            c10::static_intrusive_pointer_cast<PrepareModuleEvent>(event));
      }
      case EventType::LOCAL_GRAD_READY: {
        std::cout << "=== got LOCAL_GRAD_READY event " << std::endl << std::flush;
        return handleLocalGradReady(
            c10::static_intrusive_pointer_cast<LocalGradReadyEvent>(event));
      }
      case EventType::COMM_DONE: {
        std::cout << "=== get COMM_DONE " << std::endl << std::flush;
        return {};
      }
      default:
        TORCH_INTERNAL_ASSERT(false, "unexcepted event type");
    }
  }

 private:

  std::vector<std::shared_ptr<Future>> handlePrepareModule(
      c10::intrusive_ptr<PrepareModuleEvent> event) {
    params_ = event->parameters();
    return {};
  }

  std::vector<std::shared_ptr<Future>> handleLocalGradReady(
      c10::intrusive_ptr<LocalGradReadyEvent> event) {
    std::vector<size_t> paramIndices;
    paramIndices.reserve(1);
    paramIndices.push_back(event->index());
    auto bucket = std::make_shared<Bucket>(
        event->index(), event->grad(), std::move(paramIndices));
    return createOneFutureEvent<BucketReadyEvent>(
        c10::make_intrusive<BucketReadyEvent>(std::move(bucket)));
  }


  std::vector<std::shared_ptr<Future>> handleCommDone(
      c10::intrusive_ptr<CommDoneEvent> event) {
    const auto& bucket = event->bucket();
    auto& grad = params_[bucket->index_].mutable_grad();
    if (bucket->tensor_.data_ptr() != grad.data_ptr()) {
      grad.copy_(bucket->tensor_, /*non_blocking=*/ true);
    }

    return createOneFutureEvent<GlobalGradReadyEvent>(
        c10::make_intrusive<GlobalGradReadyEvent>(bucket->index_));
  }

  std::vector<at::Tensor> params_;
};

class AllReduceComm : public EventHandler {
 public:
  AllReduceComm(c10::intrusive_ptr<c10d::ProcessGroup> pg)
      : pg_(std::move(pg)) {}

  std::vector<EventSchema> ingressEvents() override {
    return {EventType::BUCKET_READY};
  }

  std::vector<EventSchema> egressEvents() override {
    return {EventType::COMM_DONE};
  }

  std::vector<std::shared_ptr<Future>> handleEvent(
      const c10::intrusive_ptr<Event>& event) override {
    switch (event->schema().type_) {
      case EventType::BUCKET_READY: {
        std::cout << "=== got BUCKET_READY event " << std::endl << std::flush;
        return handleBucketReady(
            c10::static_intrusive_pointer_cast<BucketReadyEvent>(event));
      }
      default:
        TORCH_INTERNAL_ASSERT(false, "unexcepted event type");
    }
  }

 private:
  std::vector<std::shared_ptr<Future>> handleBucketReady(
      c10::intrusive_ptr<BucketReadyEvent> event) {
    const auto& bucket = event->bucket();
    std::vector<at::Tensor> buffers;
    buffers.reserve(1);
    buffers.push_back(bucket->tensor_);
    pg_->allreduce(buffers)->wait();
    return createOneFutureEvent<CommDoneEvent>(
        c10::make_intrusive<CommDoneEvent>(bucket));
  }

  const c10::intrusive_ptr<c10d::ProcessGroup> pg_;
};


} // namespace spmd
} // namespace distributed
} // namespace torch
